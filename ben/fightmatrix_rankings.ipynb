{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from selenium import webdriver\n",
    "# from selenium.webdriver.chrome.service import Service\n",
    "# from selenium.webdriver.chrome.options import Options\n",
    "# from selenium.webdriver.common.by import By\n",
    "# from selenium.webdriver.support.ui import WebDriverWait\n",
    "# from selenium.webdriver.support import expected_conditions as EC\n",
    "# import pandas as pd\n",
    "# import time\n",
    "\n",
    "# firefox_options = webdriver.FirefoxOptions()\n",
    "# firefox_options.add_argument('-headless')\n",
    "\n",
    "# browser = webdriver.Firefox(options=firefox_options)\n",
    "\n",
    "# start_t = time.time()\n",
    "# url = 'https://www.fightmatrix.com/historical-mma-rankings/ranking-snapshots/?Issue=878&Division=1&Page=9'\n",
    "# browser.get(url)\n",
    "\n",
    "# dfs = pd.read_html(str(browser.page_source))\n",
    "# run_t = (time.time() - start_t)/60\n",
    "# print(f\"run time: {run_t:.2f} mins\") \n",
    "\n",
    "# browser.quit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import time\n",
    "# from selenium import webdriver\n",
    "# from selenium.webdriver.common.by import By\n",
    "# from selenium.webdriver.support.ui import Select\n",
    "# from selenium.webdriver.support.ui import WebDriverWait\n",
    "# from selenium.webdriver.support import expected_conditions as EC\n",
    "# from selenium.common.exceptions import NoSuchElementException, TimeoutException\n",
    "\n",
    "# try:\n",
    "#     firefox_options = webdriver.FirefoxOptions()\n",
    "#     firefox_options.add_argument('-headless')\n",
    "\n",
    "#     driver = webdriver.Firefox(options=firefox_options)\n",
    "\n",
    "#     base_url = \"https://www.fightmatrix.com/historical-mma-rankings/generated-historical-rankings/?Issue={}&Division={}&Page={}\"\n",
    "\n",
    "#     columns = [\"snapshot_periods\", \"weight_classes\", \"rank\", \"name\", \"country\", \"points\"]\n",
    "#     data = []\n",
    "\n",
    "#     weight_classes = [1, 2, 3, 4, 5, 6, 7, 8, 9, 12, 13, 14, 15, 16]  # define weightclasses to obtain\n",
    "\n",
    "\n",
    "#     for division in weight_classes:\n",
    "#         issue = 135 # needs any arbitrary issue to get full list of issues from the dropdown\n",
    "#         driver.get(base_url.format(issue, division, 1)) \n",
    "#         try:\n",
    "#             snapshot_dropdown = Select(driver.find_element(By.NAME, \"Issue\"))\n",
    "#             snapshot_periods = [option.get_attribute(\"value\") for option in snapshot_dropdown.options if option.get_attribute(\"value\")]\n",
    "#             max_pages_per_snapshot = 25\n",
    "#             start_t = time.time()\n",
    "#             run_t = 0\n",
    "#             for issue in snapshot_periods:\n",
    "#                 page = 1\n",
    "#                 while page <= max_pages_per_snapshot: \n",
    "#                     url = base_url.format(issue, division, page)\n",
    "#                     driver.get(url)\n",
    "#                     print(\"Current URL:\", url)\n",
    "#                     try:\n",
    "#                         WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, \"//table[@class='tblRank']//tbody/tr\")))\n",
    "#                         rows = driver.find_elements(By.XPATH, \"//tbody/tr[td[@class='tdRank']]\")\n",
    "#                         rows_alt = driver.find_elements(By.XPATH, \"//tbody/tr[td[@class='tdRankAlt']]\")\n",
    "#                         combined_rows = rows + rows_alt\n",
    "#                         print(\"Number of rows:\", len(combined_rows))\n",
    "#                         if len(combined_rows) == 0:\n",
    "#                             run_t = (time.time() - start_t)/60 - run_t\n",
    "#                             print(f\"snapshot done: {run_t:.2f} mins\")  \n",
    "#                             break\n",
    "#                         for row in rows:\n",
    "#                             rank = row.find_element(By.CLASS_NAME, \"tdRank\").text\n",
    "#                             name = row.find_element(By.CLASS_NAME, \"sherLink\").text\n",
    "#                             country = row.find_element(By.TAG_NAME, \"img\").get_attribute(\"src\").split(\"/\")[-1].split(\".\")[0]\n",
    "#                             points = row.find_element(By.CLASS_NAME, \"tdBar\").text\n",
    "#                             data.append([issue, division, rank, name, country, points])\n",
    "#                         for row in rows_alt:\n",
    "#                             rank = row.find_element(By.CLASS_NAME, \"tdRankAlt\").text\n",
    "#                             name = row.find_element(By.CLASS_NAME, \"sherLink\").text\n",
    "#                             country = row.find_element(By.TAG_NAME, \"img\").get_attribute(\"src\").split(\"/\")[-1].split(\".\")[0]\n",
    "#                             points = row.find_element(By.CLASS_NAME, \"tdBar\").text\n",
    "#                             data.append([issue, division, rank, name, country, points])\n",
    "#                     except NoSuchElementException:\n",
    "#                         print(\"NoSuchElementException for current URL\")\n",
    "#                     page += 1   \n",
    "#         except NoSuchElementException:\n",
    "#             print(\"No Issue Element Found\")\n",
    "\n",
    "#     df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "\n",
    "#     driver.quit()\n",
    "\n",
    "#     print(df)\n",
    "# #except Exception as e:\n",
    "# #    print(f\"process terminated, quitting driver: {str(e)}\")\n",
    "# finally:\n",
    "#     if 'driver' in locals() or 'driver' in globals():\n",
    "#         print(\"quitting driver\")\n",
    "#         driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from selenium import webdriver\n",
    "# firefox_options = webdriver.FirefoxOptions()\n",
    "# firefox_options.add_argument('-headless')\n",
    "# driver = webdriver.Firefox(options=firefox_options)\n",
    "# driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is to get the list of the actual values corresponding to \"issue\" or \"division\".\n",
    "# also useful to get a full list of each snapshot issue\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "dummy_site = \"https://www.fightmatrix.com/historical-mma-rankings/generated-historical-rankings/?Issue=1&Division=1&Page=1\"\n",
    "html = requests.get(dummy_site).text\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "select_iss = soup.find('select', attrs={'name': 'Issue'})\n",
    "select_div = soup.find('select', attrs={'name': 'Division'})\n",
    "\n",
    "issue_list = []\n",
    "div_list = []\n",
    "\n",
    "\n",
    "for option in select_iss.find_all('option'):\n",
    "    value = option['value']\n",
    "    text = option.get_text(strip=True)\n",
    "    issue_list.append((value, text))\n",
    "\n",
    "for option in select_div.find_all('option'):\n",
    "    value = option['value']\n",
    "    text = option.get_text(strip=True)\n",
    "    div_list.append((value, text))\n",
    "\n",
    "issue_df = pd.DataFrame(issue_list, columns=['issue', 'date'])\n",
    "div_df = pd.DataFrame(div_list, columns=['division', 'weightclass'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "base_url = \"https://www.fightmatrix.com/historical-mma-rankings/generated-historical-rankings/?Issue={}&Division={}&Page={}\"\n",
    "division = [1, 2, 3, 4, 5, 6, 7, 8, 9, 12, 13, 14, 15, 16] # could also use div_df['weightclass']\n",
    "issue = issue_df['issue'] # 128 for testing\n",
    "\n",
    "rank_data = []\n",
    "fighter_data = []\n",
    "record_data = []\n",
    "points_data = []\n",
    "country_data = []\n",
    "division_data = []\n",
    "issue_data = []\n",
    "\n",
    "for div in division:\n",
    "    for iss in issue:\n",
    "        page = 1\n",
    "        while True:\n",
    "            url = base_url.format(iss, div, page)\n",
    "            response = requests.get(url)\n",
    "\n",
    "            if response.status_code == 200:\n",
    "                html = response.text\n",
    "\n",
    "                soup = BeautifulSoup(html, 'html.parser')\n",
    "                table = soup.find('table', class_='tblRank')\n",
    "\n",
    "                # important:\n",
    "                # if page is blank, skip to the next issue (stops it from adding pages to loop through for an issue)\n",
    "                if len(table.find_all('tr')[1:]) == 0:\n",
    "                    print(f\"no more data for issue {iss}, div {div}.\")\n",
    "                    break\n",
    "\n",
    "                for row in table.find_all('tr')[1:]:  # skip header \n",
    "                    cells = row.find_all(['td', 'a', 'div']) \n",
    "                    rank = cells[0].text.strip() if cells[0].text.strip() else None\n",
    "                    country = cells[2].find('img')['src'].split('/')[-1].split('.')[0]\n",
    "                    fighter = row.find(class_='sherLink').strong.text.strip()\n",
    "                    record = cells[4].text.strip() if cells[4].text.strip() else None\n",
    "                    points = row.find(class_='tdBar').text.strip()\n",
    "\n",
    "                    rank_data.append(rank)\n",
    "                    fighter_data.append(fighter)\n",
    "                    country_data.append(country)\n",
    "                    record_data.append(record)\n",
    "                    points_data.append(points)\n",
    "                    division_data.append(div)\n",
    "                    issue_data.append(iss)\n",
    "\n",
    "                time.sleep(0.25) # delay\n",
    "\n",
    "                print(f\"issue {iss}, division {div}, p {page}\")\n",
    "                page += 1\n",
    "            else:\n",
    "                print(f\"Failed to retrieve the webpage for Issue {iss}, Division {div}.\")\n",
    "                break\n",
    "\n",
    "        print(f\"done: issue {iss} div {div}\")\n",
    "\n",
    "    print(f\"done: div {div}\")\n",
    "\n",
    "# Create a Pandas DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Issue': issue_data,\n",
    "    'Division': division_data,\n",
    "    'Rank': rank_data,\n",
    "    'Country': country_data,\n",
    "    'Fighter': fighter_data,\n",
    "    'Record': record_data,\n",
    "    'Points': points_data\n",
    "})\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if terminated early:\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Issue': issue_data,\n",
    "    'Division': division_data,\n",
    "    'Rank': rank_data,\n",
    "    'Country': country_data,\n",
    "    'Fighter': fighter_data,\n",
    "    'Record': record_data,\n",
    "    'Points': points_data\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
